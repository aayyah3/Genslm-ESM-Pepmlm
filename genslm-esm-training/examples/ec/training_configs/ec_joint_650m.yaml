training_args:
  output_dir: /lus/eagle/projects/CVD-Mol-AI/braceal/src/genslm-esm/runs/ec_prod/ec_joint_650m
  num_train_epochs: 200 # Double the number of epochs to have the same number of steps as the other runs
  per_device_train_batch_size: 2 # Smaller batch size than the other runs
  per_device_eval_batch_size: 2
  gradient_accumulation_steps: 1
  dataloader_num_workers: 8
  eval_steps: 500
  logging_steps: 500
  save_steps: 500
  label_names: ["labels"]

compute_codon_loss: true
compute_aminoacid_loss: true
compute_contrastive_loss: false
contrastive_temperature: 0.1
contrastive_pooler: mean
base_model: facebook/esm2_t33_650M_UR50D
tokenizer_path: /lus/eagle/projects/CVD-Mol-AI/braceal/src/genslm-esm/tokenizer_esm_genslm
train_path: /lus/eagle/projects/CVD-Mol-AI/braceal/src/genslm-esm/examples/ec/ec_data_v1/ec_v1_train.fasta
eval_path: /lus/eagle/projects/CVD-Mol-AI/braceal/src/genslm-esm/examples/ec/ec_data_v1/ec_v1_valid.fasta
wandb_project: genslm-esm-ec-prod-experiments
